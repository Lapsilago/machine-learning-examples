{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition (LSTM):** An LSTM is defined by\n",
    "* a number $m$ of units and a number $k$ of features\n",
    "* a $4$-tuple of matrices $W_i, W_f, W_c, W_o \\in \\mathbb{R}^{k \\times m}$ called *input, forget, cell and output kernels*,\n",
    "* a $4$-tuple of matrices $U_i, U_f, U_c, U_o \\in \\mathbb{R}^{m \\times m}$ called *input, forget, cell and output recurrent kernels*,\n",
    "* a $4$-tuple of vectors $b_i, b_f, b_c, b_o \\in \\mathbb{R}^{m}$ called *input, forget, cell and output bias*,\n",
    "* two function $\\sigma, \\tau:\\mathbb{R} \\to \\mathbb{R}$ called *activation* and *recurrent activation*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition (feedforward):** Let $x_1, \\ldots, x_T \\in \\mathbb{R}^{k} \\cong \\mathbb{R}^{1 \\times k}$ be an input sequence. Then $h_t$\n",
    "\n",
    "\\begin{align}\n",
    "i_t &:= \\tau(x_t W_i + h_{t-1} U_i + b_i) \\in \\mathbb{R}^m\\\\\n",
    "f_t &:= \\tau(x_t W_f + h_{t-1} U_f + b_f) \\in \\mathbb{R}^m\\\\\n",
    "\\tilde c_t &:= \\sigma(x_t W_c + h_{t-1} U_c + b_c) \\in \\mathbb{R}^m \\\\\n",
    "c_t &:= f_t c_{t-1} + i_t \\tilde c_t \\\\\n",
    "o_t &:= \\tau(x_t W_o  + h_{t-1} U_o + b_0) \\\\\n",
    "h_t & := o_t \\tau(c_t) \\in \\mathbb{R}^m\n",
    "\\end{align}\n",
    "\n",
    "where we employ the conventions $h_{-1} := c_{-1} := 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical Illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "Seting up an LSTM in `keras` is straightforward as `keras` has a pre-defined `LSTM` layer for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "num_units = 3\n",
    "num_time_steps = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(num_time_steps,num_features),\n",
    "               units=num_units,\n",
    "               activation='tanh',\n",
    "               recurrent_activation='sigmoid',\n",
    "               use_bias=True))\n",
    "model.compile(optimizer='adam', loss='MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 3)                 72        \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.51042557,  0.5942211 ,  0.45578587,  0.43169022, -0.34372836,\n",
       "         -0.11740583, -0.07195967, -0.02087122, -0.5128101 , -0.04139394,\n",
       "          0.27040482, -0.42312205],\n",
       "        [ 0.6315795 ,  0.5031016 ,  0.4387064 , -0.06581646,  0.3208986 ,\n",
       "         -0.01386303, -0.38648862, -0.5013469 ,  0.06860209, -0.27259246,\n",
       "          0.05693811, -0.00775212]], dtype=float32),\n",
       " array([[ 0.08577248,  0.31390995,  0.13072671,  0.12951043, -0.04111644,\n",
       "          0.21332414,  0.34374285,  0.44077843,  0.02660712,  0.5432066 ,\n",
       "         -0.08800218,  0.443929  ],\n",
       "        [ 0.03425135,  0.15008892, -0.5896042 , -0.00473604, -0.2620307 ,\n",
       "         -0.15319848, -0.4502381 , -0.05373572, -0.18822809,  0.48890838,\n",
       "          0.23610525, -0.02657015],\n",
       "        [ 0.02512891,  0.45125625, -0.01083384,  0.21070944,  0.16426632,\n",
       "         -0.03871774,  0.32860628, -0.6362487 ,  0.16737   ,  0.02314081,\n",
       "          0.41948235,  0.07368749]], dtype=float32),\n",
       " array([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(num_time_steps *num_features).reshape(num_time_steps, num_features) # this creates an input layer\n",
    "X = x[np.newaxis,:,:] # usually multiple inputs are processed, which is why this additional axis is needed\n",
    "Y = model.predict(X)  # computes the actual result\n",
    "y = Y[0] # in this example, we only have 1 output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the weights\n",
    "W, U, b = model.layers[0].get_weights()\n",
    "\n",
    "W_i = W[:, :num_units]\n",
    "W_f = W[:, num_units: num_units * 2]\n",
    "W_c = W[:, num_units * 2: num_units * 3]\n",
    "W_o = W[:, num_units * 3:]\n",
    "\n",
    "U_i = U[:, :num_units]\n",
    "U_f = U[:, num_units: num_units * 2]\n",
    "U_c = U[:, num_units * 2: num_units * 3]\n",
    "U_o = U[:, num_units * 3:]\n",
    "\n",
    "b_i = b[:num_units]\n",
    "b_f = b[num_units: num_units * 2]\n",
    "b_c = b[num_units * 2: num_units * 3]\n",
    "b_o = b[num_units * 3:]\n",
    "\n",
    "\n",
    "# setting the activations\n",
    "activation = np.tanh\n",
    "recurrent_activation = lambda x : 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-0.10198686 -0.14444107  0.02072801]] [[-0.24046278 -0.28864554  0.04164138]]\n"
     ]
    }
   ],
   "source": [
    "def lstm_feedforward_step(xt, c_tm1, h_tm1):\n",
    "    \"\"\"\n",
    "    Computes one time step in the feedforward of the LSTM.\n",
    "    \n",
    "    param xt: The input at time t; of shape (1, num_features)\n",
    "    param c_tm1: The cell state at time t-1; of shape (1, num_features)\n",
    "    param h_tm1: The carry at time t-1; of shape (1, num_features)\n",
    "    \n",
    "    returns: (h, c), i.e. a tuple with the cell state at time t and the carry state at time t; both of shape (1, num_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    i = recurrent_activation(xt @ W_i + b_i + h_tm1 @ U_i)\n",
    "    f = recurrent_activation(xt @ W_f + b_f + h_tm1 @ U_f)\n",
    "    cc = activation(xt @ W_c + b_c + h_tm1 @ U_c)\n",
    "    c = f * c_tm1 + i * cc\n",
    "    o = recurrent_activation(xt @ W_o + b_o + h_tm1 @ U_o)\n",
    "    h = o * activation(c)\n",
    "    \n",
    "    return h, c\n",
    "\n",
    "\n",
    "h_tm1 = np.zeros(num_units)\n",
    "c_tm1 = np.zeros(num_units)\n",
    "\n",
    "for t in range(num_time_steps):\n",
    "    h_tm1, c_tm1 = lstm_feedforward_step(x[np.newaxis, 0,:], c_tm1, h_tm1)\n",
    "    print(t, h_tm1, c_tm1)\n",
    "\n",
    "h = h_tm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_almost_equal(h,Y, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.10198686, -0.14444107,  0.02072801]]),\n",
       " array([[-0.10198684, -0.14444107,  0.02072801]], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/layers/recurrent/\n",
    "\n",
    "https://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "https://stackoverflow.com/questions/42861460/how-to-interpret-weights-in-a-lstm-layer-in-keras\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1863\n",
    "\n",
    "http://deeplearning.net/tutorial/lstm.html\n",
    "\n",
    "https://stackoverflow.com/questions/51199753/extract-cell-state-lstm-keras\n",
    "\n",
    "https://stats.stackexchange.com/questions/221513/why-are-the-weights-of-rnn-lstm-networks-shared-across-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
